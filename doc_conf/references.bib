@inproceedings{Chamma_NeurIPS2023,
 author = {CHAMMA, Ahmad and Engemann, Denis A. and Thirion, Bertrand},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {A. Oh and T. Naumann and A. Globerson and K. Saenko and M. Hardt and S. Levine},
 pages = {67662--67685},
 publisher = {Curran Associates, Inc.},
 title = {Statistically Valid Variable Importance Assessment through Conditional Permutations},
 url = {https://proceedings.neurips.cc/paper_files/paper/2023/file/d60e14c19cd6e0fc38556ad29ac8fbc9-Paper-Conference.pdf},
 volume = {36},
 year = {2023}
}

@article{Chamma_AAAI2024,
title={Variable Importance in High-Dimensional Settings Requires Grouping},
volume={38}, url={https://ojs.aaai.org/index.php/AAAI/article/view/28997},
DOI={10.1609/aaai.v38i10.28997},
number={10},
journal={Proceedings of the AAAI Conference on Artificial Intelligence},
author={Chamma, Ahmad and Thirion, Bertrand and Engemann, Denis},
year={2024},
month={Mar.},
pages={11195-11203}
}

@article{candesPanningGoldModelX2017,
  title = {Panning for {{Gold}}: {{Model-X Knockoffs}} for {{High-dimensional Controlled Variable Selection}}},
  shorttitle = {Panning for {{Gold}}},
  author = {Candes, Emmanuel and Fan, Yingying and Janson, Lucas and Lv, Jinchi},
  year = {2017},
  month = dec,
  journal = {arXiv:1610.02351 [math, stat]},
  eprint = {1610.02351},
  primaryclass = {math, stat},
  urldate = {2022-01-12},
  abstract = {Many contemporary large-scale applications involve building interpretable models linking a large set of potential covariates to a response in a nonlinear fashion, such as when the response is binary. Although this modeling problem has been extensively studied, it remains unclear how to effectively control the fraction of false discoveries even in high-dimensional logistic regression, not to mention general high-dimensional nonlinear models. To address such a practical problem, we propose a new framework of \$model\$-\$X\$ knockoffs, which reads from a different perspective the knockoff procedure (Barber and Cand{\textbackslash}`es, 2015) originally designed for controlling the false discovery rate in linear models. Whereas the knockoffs procedure is constrained to homoscedastic linear models with \$n{\textbackslash}ge p\$, the key innovation here is that model-X knockoffs provide valid inference from finite samples in settings in which the conditional distribution of the response is arbitrary and completely unknown. Furthermore, this holds no matter the number of covariates. Correct inference in such a broad setting is achieved by constructing knockoff variables probabilistically instead of geometrically. To do this, our approach requires the covariates be random (independent and identically distributed rows) with a distribution that is known, although we provide preliminary experimental evidence that our procedure is robust to unknown/estimated distributions. To our knowledge, no other procedure solves the \$controlled\$ variable selection problem in such generality, but in the restricted settings where competitors exist, we demonstrate the superior power of knockoffs through simulations. Finally, we apply our procedure to data from a case-control study of Crohn's disease in the United Kingdom, making twice as many discoveries as the original analysis of the same data.},
  archiveprefix = {arxiv},
  keywords = {Mathematics - Statistics Theory,Statistics - Applications,Statistics - Methodology},
  file = {/home/ahmad/Zotero/storage/YZ23F3Q5/Candes et al. - 2017 - Panning for Gold Model-X Knockoffs for High-dimen.pdf;/home/ahmad/Zotero/storage/ZSN64F6N/1610.html}
}